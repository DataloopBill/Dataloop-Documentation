{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c171e55",
   "metadata": {},
   "source": [
    "# Model Management in Dataloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71daa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Dataloop's Python Package, Torch and OS\n",
    "import dtlpy as dl\n",
    "import torch\n",
    "import os\n",
    "import adapter_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d1ed47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging in to Dataloop (checks if token expired ~24h expiration time for token)\n",
    "if dl.token_expired():\n",
    "   dl.login()\n",
    "#you can also use the simple login: \n",
    "#dl.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b75670",
   "metadata": {},
   "source": [
    "## Important Pre-requisite!\n",
    "\n",
    "Before you can use everything below, you need to create a `.py` file called `adapter_script.py` inside of your working directory (so it can be accessible), containing the following code:\n",
    "\n",
    "-----------------------------------------------------------------------------------------------\n",
    "```python\n",
    "\n",
    "import dtlpy as dl\n",
    "import torch\n",
    "import os\n",
    "@dl.Package.decorators.module(name='model-adapter',\n",
    "                              description='Model Adapter for my model',\n",
    "                              init_inputs={'model_entity': dl.Model})\n",
    "class SimpleModelAdapter(dl.BaseModelAdapter):\n",
    "    def load(self, local_path, **kwargs):\n",
    "        print('loading a model')\n",
    "        self.model = torch.load(os.path.join(local_path, 'model.pth')) #here you place your model file's name and extension\n",
    "    def predict(self, batch, **kwargs):\n",
    "        print('predicting batch of size: {}'.format(len(batch)))\n",
    "        preds = self.model(batch)\n",
    "        batch_annotations = list()\n",
    "        for i_img, predicted_class in enumerate(preds):  # annotations per image\n",
    "            image_annotations = dl.AnnotationCollection()\n",
    "            # in this example, we will assume preds is a label for a classification model\n",
    "            image_annotations.add(annotation_definition=dl.Classification(label=predicted_class),\n",
    "                                  model_info={'name': self.model_name})\n",
    "            batch_annotations.append(image_annotations)\n",
    "        return batch_annotations\n",
    "\n",
    "```\n",
    "------------------------------------------------------------------------------------------------------\n",
    "**Note:** You need to have PyTorch installed. [Find out how to install it here](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "The simplest way to create this file is to create a `.txt` file, open it, copy paste this code inside of it, and then change its file extension from `.tx`t to `.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a29ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19534279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the package\n",
    "\n",
    "import dtlpy as dl\n",
    "from adapter_script import SimpleModelAdapter\n",
    "project = dl.projects.get(project_name='CreatureHunt')\n",
    "dataset = project.datasets.get(dataset_name='Creatures')\n",
    "# codebase = project.codebases.pack(directory='<path to local dir>')\n",
    "# codebase: dl.GitCodebase = dl.GitCodebase(git_url='github.com/mygit', git_tag='v25.6.93')\n",
    "metadata = dl.Package.get_ml_metadata(cls=SimpleModelAdapter,\n",
    "                                      default_configuration={},\n",
    "                                      output_type=dl.AnnotationType.CLASSIFICATION\n",
    "                                      )\n",
    "module = dl.PackageModule.from_entry_point(entry_point='adapter_script.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cceb5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"cleanup\" in function definition: \"evaluate_model\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"with_upload\" in function definition: \"predict_dataset\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"cleanup\" in function definition: \"predict_dataset\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"batch_size\" in function definition: \"predict_dataset\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"output_shape\" in function definition: \"predict_dataset\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"upload_annotations\" in function definition: \"predict_items\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"conf_threshold\" in function definition: \"predict_items\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"batch_size\" in function definition: \"predict_items\"\n",
      "[2023-05-02 21:55:05][WAR][dtlpy:v1.76.15][repositories.packages:1613] missing input name: \"cleanup\" in function definition: \"train_model\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload Items: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Push the Package\n",
    "package = project.packages.push(package_name='package11',\n",
    "                                src_path=os.getcwd(),\n",
    "                                package_type='ml',\n",
    "                                # codebase=codebase,\n",
    "                                modules=[module],\n",
    "                                is_global=False,\n",
    "                                service_config={\n",
    "                                    'runtime': dl.KubernetesRuntime(pod_type=dl.INSTANCE_CATALOG_GPU_K80_S,\n",
    "                                                                    autoscaler=dl.KubernetesRabbitmqAutoscaler(\n",
    "                                                                        min_replicas=0,\n",
    "                                                                        max_replicas=1),\n",
    "                                                                    concurrency=1).to_json()},\n",
    "                                metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1ddca",
   "metadata": {},
   "source": [
    "## Upload artifacts and create the model\n",
    "\n",
    "Now you can create a model and upload pretrained model weights with an Artifact Item. Here, the Artfiact item is where the saved model weights are. You can upload any weights file here and name it according to the 'weights_filename' in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e41c0950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 21:55:18][WAR][dtlpy:v1.76.15][repositories.models:352] Model is using an unlocked dataset 'Creatures'. Make it readonly for training reproducibility\n"
     ]
    }
   ],
   "source": [
    "\n",
    "artifact = dl.LocalArtifact(local_path='/model.h5')\n",
    "model = package.models.create(model_name='magic-creatures_2',\n",
    "                              description='magical creatures model',\n",
    "                              tags=['pretrained', 'tutorial','onboarding'],\n",
    "                              dataset_id='63e6283b4a03c631b54725ec',\n",
    "                              configuration={'weights_filename': 'model.h5'\n",
    "                                             },\n",
    "                              project_id=package.project.id,\n",
    "                              model_artifacts=[artifact],\n",
    "                              labels=['Bear With Wings', 'Blue Panther with Wings', 'Blue Tiger With Wings','Elephant ','Fox','Giraffe','Kitty ','Koala','Lion','Unicorn']\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34299a2e",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "To deploy a model, its status must be set to trained so you can deploy a model by updating the status to trained and then deploy it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4096189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.status = 'trained'\n",
    "model.update()\n",
    "model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cac3b4",
   "metadata": {},
   "source": [
    "Now, we can actually use it to predict an Item. But first, we need to find out the model's ID and pull out an Item's ID to run the prediction on it. To find the Model's ID, you can simply print it, since we already have it as part of a variable. To find the Item id for an Item we want to run the prediction on, it's best to just open the Dataset in web and look for the Item by going on the left side of the screen (after selecting your project), clicking Data Management, Datasets, and then doubleclicking your dataset - now you should see all items in that Dataset. After clicking an Item you should see the item ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "766e7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64515c95a50ccd321591f854\n"
     ]
    }
   ],
   "source": [
    "print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cce4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bc1b2",
   "metadata": {},
   "source": [
    "Now that we have the Model ID and Item ID ready, we can execute a prediction on an item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7eff377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = dl.models.get(model_id='64515c95a50ccd321591f854')\n",
    "item = dl.items.get(item_id='63eb694cbb4d8448e0878711')\n",
    "model.deploy()\n",
    "execution = model.predict(item_ids=[item.id])\n",
    "# after a few seconds, update your execution from the cloud\n",
    "execution = dl.executions.get(execution_id=execution.id)\n",
    "# print the most recent status\n",
    "print(execution.status[-1]['status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e93cc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution(id='64515d121931d4593a9291d5', creator='myfuncont@gmail.com', created_at='2023-05-02T18:57:22.626Z', input={'items': ['63eb694cbb4d8448e0878711']}, latest_status={'timestamp': '2023-05-02T18:57:22.626Z', 'status': 'created', 'percentComplete': None, 'error': None, 'output': None}, function_name='predict_items', duration=None, attempts=0, max_attempts=3, to_terminate=False, trigger_id=None, service_id='64515c9f9d6716027513f24b', project_id='4c74c1b5-e9cb-4294-b9d5-cbfa13eda242', service_version='1.0.0', package_id='64515c8b9d6716937313f24a', package_name='package11')\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(item_ids=[item.id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7da70642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227162c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113d97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5718f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc1ee5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4ee9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dl.models.get(model_id='6450f6e1aad96a0deec8f13c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5609b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = model.predict(item_ids=[item.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1e56b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution(id='6450f71482d4277ba2f2a2ba', creator='myfuncont@gmail.com', created_at='2023-05-02T11:42:12.140Z', input={'items': ['63eb694cbb4d8448e0878711']}, latest_status={'timestamp': '2023-05-02T11:42:12.140Z', 'status': 'created', 'percentComplete': None, 'error': None, 'output': None}, function_name='predict_items', duration=None, attempts=0, max_attempts=3, to_terminate=False, trigger_id=None, service_id='6450f6ea014e51186820e1ad', project_id='4c74c1b5-e9cb-4294-b9d5-cbfa13eda242', service_version='1.0.0', package_id='644f8e764f2d0c2cdf52b438', package_name='package1')\n"
     ]
    }
   ],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36e53aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='63e6283b4a03c631b54725ec', url='https://gate.dataloop.ai/api/v1/datasets/63e6283b4a03c631b54725ec', name='Creatures', creator='myfuncont@gmail.com', items_count=1132, expiration_options=None, index_driver='v1', created_at='2023-02-10T11:19:23.239Z')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0490aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Items: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s]\n",
      "loading a model\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'H'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m package \u001b[38;5;241m=\u001b[39m dl\u001b[38;5;241m.\u001b[39mpackages\u001b[38;5;241m.\u001b[39mget(package_id\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpackage_id)\n\u001b[0;32m      2\u001b[0m adapter \u001b[38;5;241m=\u001b[39m package\u001b[38;5;241m.\u001b[39mbuild(module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-adapter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\dtlpy\\ml\\base_model_adapter.py:251\u001b[0m, in \u001b[0;36mBaseModelAdapter.load_from_model\u001b[1;34m(self, model_entity, local_path, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_entity\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[0;32m    247\u001b[0m     local_path\u001b[38;5;241m=\u001b[39mlocal_path,\n\u001b[0;32m    248\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifacts_path\u001b[39m\u001b[38;5;124m'\u001b[39m: local_path})\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(local_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.dataloop\\packages\\package1-644f8e764f2d0c2cdf52b438\\1.0.5\\adapter_script.py:10\u001b[0m, in \u001b[0;36mSimpleModelAdapter.load\u001b[1;34m(self, local_path, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, local_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading a model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\serialization.py:1002\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1002\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, 'H'."
     ]
    }
   ],
   "source": [
    "\n",
    "package = dl.packages.get(package_id=model.package_id)\n",
    "adapter = package.build(module_name='model-adapter')\n",
    "adapter.load_from_model(model_entity=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594782c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f562c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
